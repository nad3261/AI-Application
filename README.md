This repository contains an AI application designed to fetch and preprocess data from Wikipedia, along with a modular data preprocessing pipeline that can be applied to various datasets for further analysis and machine learning tasks.

Business Case

Problem

Educational platforms often struggle to efficiently categorize learning materials, which can make it difficult for students to find relevant resources quickly and easily.

Solution

By automatically categorizing materials into well-defined subjects like "Mathematics", "History", "Science", etc., the platform can provide a more organized and accessible library of resources. This project aims to address this challenge by building a solution that can classify educational content, making it easier for students to find materials tailored to their studies.

Project Overview

This project consists of two main components:

Data Fetching: A Jupyter notebook (Fetching_data_from_Wikipedia.ipynb) that retrieves data from Wikipedia and prepares it for downstream tasks.

Data Preprocessing: A Python script (Data preprocessing/data preprocessing.py) that defines a DataPreprocessing class for data cleaning, feature engineering, and transformation.

Key Features:Fetches and cleans data from Wikipedia.

Modularized data preprocessing pipeline.

Ready for integration with machine learning models.
